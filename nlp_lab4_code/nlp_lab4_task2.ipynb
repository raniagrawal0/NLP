{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fadb446-de37-4447-a6f7-18aece5e6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add-One (Laplace) Smoothing\n",
    "def add_one_smoothing(ngram_counts, vocab_size):\n",
    "    \n",
    "    total_count = sum(ngram_counts.values())\n",
    "    smoothed_probs = {}\n",
    "    for ngram, count in ngram_counts.items():\n",
    "        smoothed_probs[ngram] = (count + 1) / (total_count + vocab_size)\n",
    "    return smoothed_probs\n",
    "\n",
    "\n",
    "# Add-k Smoothing\n",
    "def add_k_smoothing(ngram_counts, vocab_size, k=0.5):\n",
    "    \n",
    "    total_count = sum(ngram_counts.values())\n",
    "    smoothed_probs = {}\n",
    "    for ngram, count in ngram_counts.items():\n",
    "        smoothed_probs[ngram] = (count + k) / (total_count + k * vocab_size)\n",
    "    return smoothed_probs\n",
    "\n",
    "\n",
    "# Add Token Type Smoothing\n",
    "def add_token_type_smoothing(ngram_counts, token_types):\n",
    "  \n",
    "    total_count = sum(ngram_counts.values())\n",
    "    smoothed_values = {}\n",
    "    for ngram, count in ngram_counts.items():\n",
    "        smoothed_values[ngram] = (count + token_types) / (total_count + token_types)\n",
    "    return smoothed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc722ba-5d25-4113-ba31-62cb5ce2cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_ngrams_from_txt(file_name):\n",
    "    from collections import Counter\n",
    "    counter = Counter()\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            ngram, freq = parts\n",
    "            freq = int(freq)\n",
    "            tokens = tuple(ngram.split()) if \" \" in ngram else ngram\n",
    "            counter[tokens] = freq\n",
    "    return counter\n",
    "def save_ngrams_to_txt(counter, file_name):\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ngram, value in counter.items():\n",
    "            if isinstance(ngram, tuple):\n",
    "                ngram_str = \" \".join(ngram)\n",
    "            else:\n",
    "                ngram_str = ngram\n",
    "            f.write(f\"{ngram_str}\\t{value}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: do it for unigrams\n",
    "    unigrams = load_ngrams_from_txt(\"unigrams.txt\")\n",
    "    vocab_size = len(unigrams)\n",
    "\n",
    "    uni_add1 = add_one_smoothing(unigrams, vocab_size)\n",
    "    uni_addk = add_k_smoothing(unigrams, vocab_size, k=0.5)\n",
    "    uni_toktype = add_token_type_smoothing(unigrams, vocab_size)\n",
    "\n",
    "    save_ngrams_to_txt(uni_add1, \"unigrams_add1.txt\")\n",
    "    save_ngrams_to_txt(uni_addk, \"unigrams_addk.txt\")\n",
    "    save_ngrams_to_txt(uni_toktype, \"unigrams_toktype.txt\")\n",
    "\n",
    "    print(\"âœ… Smoothed unigram models saved!\")\n",
    "\n",
    "    # Repeat for bigrams, trigrams, quadrigrams\n",
    "    for name in [\"bigrams\", \"trigrams\", \"quadrigrams\"]:\n",
    "        print(f\"Processing {name}...\")\n",
    "        counts = load_ngrams_from_txt(f\"{name}.txt\")\n",
    "        vocab_size = len(counts)\n",
    "\n",
    "        add1 = add_one_smoothing(counts, vocab_size)\n",
    "        addk = add_k_smoothing(counts, vocab_size, k=0.5)\n",
    "        toktype = add_token_type_smoothing(counts, vocab_size)\n",
    "\n",
    "        save_ngrams_to_txt(add1, f\"{name}_add1.txt\")\n",
    "        save_ngrams_to_txt(addk, f\"{name}_addk.txt\")\n",
    "        save_ngrams_to_txt(toktype, f\"{name}_toktype.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cbd95c5-bb7b-4062-b1cc-6735ca565d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing quadrigrams...\n",
      "Processing add1\n",
      "Processing add_k\n",
      "Processing add_token_type\n"
     ]
    }
   ],
   "source": [
    "for name in [\"quadrigrams\"]:\n",
    "        print(f\"Processing {name}...\")\n",
    "        counts = load_ngrams_from_txt(f\"{name}.txt\")\n",
    "        vocab_size = len(counts)\n",
    "\n",
    "        print(f\"Processing add1\")\n",
    "        add1 = add_one_smoothing(counts, vocab_size)\n",
    "        print(f\"Processing add_k\")\n",
    "        addk = add_k_smoothing(counts, vocab_size, k=0.5)\n",
    "        print(f\"Processing add_token_type\")\n",
    "        toktype = add_token_type_smoothing(counts, vocab_size)\n",
    "\n",
    "        save_ngrams_to_txt(add1, f\"{name}_add1.txt\")\n",
    "        save_ngrams_to_txt(addk, f\"{name}_addk.txt\")\n",
    "        save_ngrams_to_txt(toktype, f\"{name}_toktype.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be678815-4e99-450a-9837-ecf63fd3cd25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
