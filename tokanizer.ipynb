{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b41696d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c2d5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91630\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Directly stream the Hindi-Devanagari split\n",
    "hindi_stream = load_dataset(\n",
    "    \"ai4bharat/IndicCorpV2\",\n",
    "    \"indiccorp_v2\",\n",
    "    streaming=True,\n",
    "    split=\"hin_Deva\"  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3863ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\91630\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91630\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d43c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# Example: Get first 5 entries from the iterable\n",
    "samples = list(islice(hindi_stream, 5))  # change 5 to any number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947bf6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = samples[0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf95337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def hindi_tokenizer(text):\n",
    "    url_pattern = r'https?://[^\\s]+|www\\.[^\\s]+'\n",
    "    email_pattern = r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,4}\\b'\n",
    "\n",
    "    # Save and replace URLs and emails\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    text = re.sub(url_pattern, '<URL>', text)\n",
    "\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    text = re.sub(email_pattern, '<EMAIL>', text)\n",
    "\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token == '<URL>':\n",
    "            tokens.append(urls.pop(0))\n",
    "        elif token == '<EMAIL>':\n",
    "            tokens.append(emails.pop(0))\n",
    "        else:\n",
    "            split_tokens = re.findall(\n",
    "                r'[\\u0900-\\u097F]+|[a-zA-Z0-9]+|[।.,!?;:()\\\"\\'\\-]|[^\\s]',\n",
    "                token\n",
    "            )\n",
    "            tokens.extend(split_tokens)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def hindi_sentence_tokenizer(text):\n",
    "    sentence_end_pattern = r'(?<=[।!?\\.])\\s+'\n",
    "    sentences = re.split(sentence_end_pattern, text.strip())\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def detokenize(tokens):\n",
    "    # Rebuild sentence with proper spacing logic\n",
    "    sentence = ''\n",
    "    for i, token in enumerate(tokens):\n",
    "        if i > 0 and not re.match(r'[।.,!?;:)\\]\\'\\\"]', token):\n",
    "            sentence += ' '\n",
    "        sentence += token\n",
    "    return sentence.strip()\n",
    "\n",
    "def hindi_corpus_statistics(text):\n",
    "    sentences = hindi_sentence_tokenizer(text)\n",
    "    all_tokens = []\n",
    "    reconstructed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = hindi_tokenizer(sentence)\n",
    "        all_tokens.extend(tokens)\n",
    "\n",
    "        # For checking reformation\n",
    "        reconstructed = detokenize(tokens)\n",
    "        reconstructed_sentences.append(reconstructed)\n",
    "\n",
    "    num_tokens = len(all_tokens)\n",
    "    unique_tokens = set(all_tokens)\n",
    "    total_chars = sum(len(token) for token in all_tokens)\n",
    "\n",
    "    word_tokens = [t for t in all_tokens if re.match(r'^[\\u0900-\\u097F\\w]+$', t)]\n",
    "    avg_word_length = sum(len(t) for t in word_tokens) / len(word_tokens) if word_tokens else 0\n",
    "    type_token_ratio = len(unique_tokens) / num_tokens if num_tokens else 0\n",
    "\n",
    "    return {\n",
    "        'sentences': sentences,\n",
    "        'tokens': all_tokens,\n",
    "        'num_tokens': num_tokens,\n",
    "        'total_characters': total_chars,\n",
    "        'average_word_length': round(avg_word_length, 2),\n",
    "        'type_token_ratio': round(type_token_ratio, 3),\n",
    "        'reconstructed_sentences': reconstructed_sentences\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0f3048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentences:\n",
      "लोगों को बिलों संबंधी सुविधा देना ही उनका काम  इनेलो 1987 में उस वक्त ऐसे ही दोराहे पर खड़ी थी, जब पूर्व उपप्रधानमंत्री देवीलाल ने अपने पुत्र ओमप्रकाश चौटाला को अपना राजनीतिक उत्तराधिकारी घोषित किया था।\n",
      "हालांकि तब पार्टी पर देवीलाल की मजबूत पकड़ के चलते पार्टी टूटने से बच गई थी।\n",
      "1989 में देवीलाल केन्द्र की राजनीति में सक्रिय हो गए थे और उनके उपप्रधानमंत्री बनने के पश्चात् उनके तीन बेटों जगदीश सिंह, रणजीत सिंह और ओमप्रकाश चौटाला में से रणजीत और ओमप्रकाश के बीच हरियाणा में उनकी राजनीतिक विरासत को लेकर जंग शुरू हो गई थी।\n",
      "उन परिस्थितियों में देवीलाल ने कड़ा निर्णय लेते हुए पार्टी की बागडोर ओमप्रकाश चौटाला के हवाले कर दी थी, जिसके बाद रणजीत की बगावत का असर पार्टी, संगठन और उनकी सरकार पर भी पड़ा था।\n",
      "उस समय रणजीत की नाराजगी के चलते उनके समर्थन में कई कैबिनेट मंत्रियों ने इस्तीफे दे दिए थे किन्तु तब पार्टी सुप्रीमो चौ.\n",
      "देवीलाल की हरियाणा की जनता पर इतनी मजबूत पकड़ थी कि ओमप्रकाश चौटाला को उत्तराधिकारी बनाने के उनके फैसले का जनता के बीच कोई खास विरोध नहीं हुआ था लेकिन आज स्थिति बिल्कुल विपरीत है।\n",
      "ओमप्रकाश चौटाला पिछले काफी समय से जेल में हैं और जेल में रहते पार्टी के साथ-साथ परिवार पर भी उनकी पकड़ काफी ढ़ीली हो गई है, इसी कारण उनमें अब देवीलाल जैसा वो सामर्थ्य नजर नहीं आता कि वे अपने फैसलों को बगैर किसी प्रतिरोध के लागू करा सकें।\n",
      "जहां आई थी तबाही उस घाटी क्षेत्र में खतरा ज्यादा\n",
      "\n",
      "Reconstructed Sentences:\n",
      "लोगों को बिलों संबंधी सुविधा देना ही उनका काम इनेलो 1987 में उस वक्त ऐसे ही दोराहे पर खड़ी थी, जब पूर्व उपप्रधानमंत्री देवीलाल ने अपने पुत्र ओमप्रकाश चौटाला को अपना राजनीतिक उत्तराधिकारी घोषित किया था।\n",
      "हालांकि तब पार्टी पर देवीलाल की मजबूत पकड़ के चलते पार्टी टूटने से बच गई थी।\n",
      "1989 में देवीलाल केन्द्र की राजनीति में सक्रिय हो गए थे और उनके उपप्रधानमंत्री बनने के पश्चात् उनके तीन बेटों जगदीश सिंह, रणजीत सिंह और ओमप्रकाश चौटाला में से रणजीत और ओमप्रकाश के बीच हरियाणा में उनकी राजनीतिक विरासत को लेकर जंग शुरू हो गई थी।\n",
      "उन परिस्थितियों में देवीलाल ने कड़ा निर्णय लेते हुए पार्टी की बागडोर ओमप्रकाश चौटाला के हवाले कर दी थी, जिसके बाद रणजीत की बगावत का असर पार्टी, संगठन और उनकी सरकार पर भी पड़ा था।\n",
      "उस समय रणजीत की नाराजगी के चलते उनके समर्थन में कई कैबिनेट मंत्रियों ने इस्तीफे दे दिए थे किन्तु तब पार्टी सुप्रीमो चौ.\n",
      "देवीलाल की हरियाणा की जनता पर इतनी मजबूत पकड़ थी कि ओमप्रकाश चौटाला को उत्तराधिकारी बनाने के उनके फैसले का जनता के बीच कोई खास विरोध नहीं हुआ था लेकिन आज स्थिति बिल्कुल विपरीत है।\n",
      "ओमप्रकाश चौटाला पिछले काफी समय से जेल में हैं और जेल में रहते पार्टी के साथ - साथ परिवार पर भी उनकी पकड़ काफी ढ़ीली हो गई है, इसी कारण उनमें अब देवीलाल जैसा वो सामर्थ्य नजर नहीं आता कि वे अपने फैसलों को बगैर किसी प्रतिरोध के लागू करा सकें।\n",
      "जहां आई थी तबाही उस घाटी क्षेत्र में खतरा ज्यादा\n",
      "\n",
      "Tokens: ['लोगों', 'को', 'बिलों', 'संबंधी', 'सुविधा', 'देना', 'ही', 'उनका', 'काम', 'इनेलो', '1987', 'में', 'उस', 'वक्त', 'ऐसे', 'ही', 'दोराहे', 'पर', 'खड़ी', 'थी', ',', 'जब', 'पूर्व', 'उपप्रधानमंत्री', 'देवीलाल', 'ने', 'अपने', 'पुत्र', 'ओमप्रकाश', 'चौटाला', 'को', 'अपना', 'राजनीतिक', 'उत्तराधिकारी', 'घोषित', 'किया', 'था।', 'हालांकि', 'तब', 'पार्टी', 'पर', 'देवीलाल', 'की', 'मजबूत', 'पकड़', 'के', 'चलते', 'पार्टी', 'टूटने', 'से', 'बच', 'गई', 'थी।', '1989', 'में', 'देवीलाल', 'केन्द्र', 'की', 'राजनीति', 'में', 'सक्रिय', 'हो', 'गए', 'थे', 'और', 'उनके', 'उपप्रधानमंत्री', 'बनने', 'के', 'पश्चात्', 'उनके', 'तीन', 'बेटों', 'जगदीश', 'सिंह', ',', 'रणजीत', 'सिंह', 'और', 'ओमप्रकाश', 'चौटाला', 'में', 'से', 'रणजीत', 'और', 'ओमप्रकाश', 'के', 'बीच', 'हरियाणा', 'में', 'उनकी', 'राजनीतिक', 'विरासत', 'को', 'लेकर', 'जंग', 'शुरू', 'हो', 'गई', 'थी।', 'उन', 'परिस्थितियों', 'में', 'देवीलाल', 'ने', 'कड़ा', 'निर्णय', 'लेते', 'हुए', 'पार्टी', 'की', 'बागडोर', 'ओमप्रकाश', 'चौटाला', 'के', 'हवाले', 'कर', 'दी', 'थी', ',', 'जिसके', 'बाद', 'रणजीत', 'की', 'बगावत', 'का', 'असर', 'पार्टी', ',', 'संगठन', 'और', 'उनकी', 'सरकार', 'पर', 'भी', 'पड़ा', 'था।', 'उस', 'समय', 'रणजीत', 'की', 'नाराजगी', 'के', 'चलते', 'उनके', 'समर्थन', 'में', 'कई', 'कैबिनेट', 'मंत्रियों', 'ने', 'इस्तीफे', 'दे', 'दिए', 'थे', 'किन्तु', 'तब', 'पार्टी', 'सुप्रीमो', 'चौ', '.', 'देवीलाल', 'की', 'हरियाणा', 'की', 'जनता', 'पर', 'इतनी', 'मजबूत', 'पकड़', 'थी', 'कि', 'ओमप्रकाश', 'चौटाला', 'को', 'उत्तराधिकारी', 'बनाने', 'के', 'उनके', 'फैसले', 'का', 'जनता', 'के', 'बीच', 'कोई', 'खास', 'विरोध', 'नहीं', 'हुआ', 'था', 'लेकिन', 'आज', 'स्थिति', 'बिल्कुल', 'विपरीत', 'है।', 'ओमप्रकाश', 'चौटाला', 'पिछले', 'काफी', 'समय', 'से', 'जेल', 'में', 'हैं', 'और', 'जेल', 'में', 'रहते', 'पार्टी', 'के', 'साथ', '-', 'साथ', 'परिवार', 'पर', 'भी', 'उनकी', 'पकड़', 'काफी', 'ढ़ीली', 'हो', 'गई', 'है', ',', 'इसी', 'कारण', 'उनमें', 'अब', 'देवीलाल', 'जैसा', 'वो', 'सामर्थ्य', 'नजर', 'नहीं', 'आता', 'कि', 'वे', 'अपने', 'फैसलों', 'को', 'बगैर', 'किसी', 'प्रतिरोध', 'के', 'लागू', 'करा', 'सकें।', 'जहां', 'आई', 'थी', 'तबाही', 'उस', 'घाटी', 'क्षेत्र', 'में', 'खतरा', 'ज्यादा']\n",
      "Number of Tokens: 258\n",
      "Total Characters: 1039\n",
      "Average Word Length: 4.11\n",
      "Type-Token Ratio: 0.597\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(sample['text'] for sample in samples)\n",
    "stats = hindi_corpus_statistics(text)\n",
    "\n",
    "print(\"Original Sentences:\")\n",
    "for sentence in stats['sentences']:\n",
    "    print(sentence)\n",
    "\n",
    "print(\"\\nReconstructed Sentences:\")\n",
    "for sent in stats['reconstructed_sentences']:\n",
    "    print(sent)\n",
    "\n",
    "print(\"\\nTokens:\", stats['tokens'])\n",
    "print(\"Number of Tokens:\", stats['num_tokens'])\n",
    "print(\"Total Characters:\", stats['total_characters'])\n",
    "print(\"Average Word Length:\", stats['average_word_length'])\n",
    "print(\"Type-Token Ratio:\", stats['type_token_ratio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e5b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def english_tokenizer(text):\n",
    "    # Define patterns\n",
    "    url_pattern = r'https?://[^\\s]+|www\\.[^\\s]+'\n",
    "    email_pattern = r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,}\\b'\n",
    "\n",
    "    # Save and replace URLs/emails\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    text = re.sub(url_pattern, '<URL>', text)\n",
    "\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    text = re.sub(email_pattern, '<EMAIL>', text)\n",
    "\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token == '<URL>':\n",
    "            tokens.append(urls.pop(0))\n",
    "        elif token == '<EMAIL>':\n",
    "            tokens.append(emails.pop(0))\n",
    "        else:\n",
    "            # Tokenize: words, numbers, punctuation\n",
    "            split_tokens = re.findall(r\"[a-zA-Z0-9]+|[.,!?;:'\\\"()\\-]|[^\\s]\", token)\n",
    "            tokens.extend(split_tokens)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def english_sentence_tokenizer(text):\n",
    "    # Split on sentence-ending punctuation followed by space\n",
    "    sentence_end_pattern = r'(?<=[.!?])\\s+'\n",
    "    sentences = re.split(sentence_end_pattern, text.strip())\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def detokenize(tokens):\n",
    "    sentence = ''\n",
    "    for i, token in enumerate(tokens):\n",
    "        if i > 0 and not re.match(r'[.,!?;:)\\]\\'\\\"]', token):\n",
    "            sentence += ' '\n",
    "        sentence += token\n",
    "    return sentence.strip()\n",
    "\n",
    "def english_corpus_statistics(text):\n",
    "    sentences = english_sentence_tokenizer(text)\n",
    "    all_tokens = []\n",
    "    reconstructed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = english_tokenizer(sentence)\n",
    "        all_tokens.extend(tokens)\n",
    "\n",
    "        reconstructed = detokenize(tokens)\n",
    "        reconstructed_sentences.append(reconstructed)\n",
    "\n",
    "    num_tokens = len(all_tokens)\n",
    "    unique_tokens = set(all_tokens)\n",
    "    total_chars = sum(len(token) for token in all_tokens)\n",
    "\n",
    "    word_tokens = [t for t in all_tokens if re.match(r'^[a-zA-Z0-9]+$', t)]\n",
    "    avg_word_length = sum(len(t) for t in word_tokens) / len(word_tokens) if word_tokens else 0\n",
    "    type_token_ratio = len(unique_tokens) / num_tokens if num_tokens else 0\n",
    "\n",
    "    return {\n",
    "        'sentences': sentences,\n",
    "        'tokens': all_tokens,\n",
    "        'num_tokens': num_tokens,\n",
    "        'total_characters': total_chars,\n",
    "        'average_word_length': round(avg_word_length, 2),\n",
    "        'type_token_ratio': round(type_token_ratio, 3),\n",
    "        'reconstructed_sentences': reconstructed_sentences\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe7ae645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentences:\n",
      "Hi!\n",
      "My name is John.\n",
      "Email me at john.doe@example.com or visit https://openai.com.\n",
      "This is amazing, isn't it?\n",
      "Let's test URLs like www.testsite.com too.\n",
      "\n",
      "Reconstructed Sentences:\n",
      "Hi!\n",
      "My name is John.\n",
      "Email me at john.doe@example.com or visit https://openai.com.\n",
      "This is amazing, isn' t it?\n",
      "Let' s test URLs like www.testsite.com too.\n",
      "\n",
      "Tokens: ['Hi', '!', 'My', 'name', 'is', 'John', '.', 'Email', 'me', 'at', 'john.doe@example.com', 'or', 'visit', 'https://openai.com.', 'This', 'is', 'amazing', ',', 'isn', \"'\", 't', 'it', '?', 'Let', \"'\", 's', 'test', 'URLs', 'like', 'www.testsite.com', 'too', '.']\n",
      "Number of Tokens: 32\n",
      "Total Characters: 130\n",
      "Average Word Length: 3.09\n",
      "Type-Token Ratio: 0.906\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Hi! My name is John. Email me at john.doe@example.com or visit https://openai.com. \n",
    "This is amazing, isn't it? Let's test URLs like www.testsite.com too.\"\"\"\n",
    "\n",
    "stats = english_corpus_statistics(text)\n",
    "\n",
    "print(\"Original Sentences:\")\n",
    "for s in stats['sentences']:\n",
    "    print(s)\n",
    "\n",
    "print(\"\\nReconstructed Sentences:\")\n",
    "for s in stats['reconstructed_sentences']:\n",
    "    print(s)\n",
    "\n",
    "print(\"\\nTokens:\", stats['tokens'])\n",
    "print(\"Number of Tokens:\", stats['num_tokens'])\n",
    "print(\"Total Characters:\", stats['total_characters'])\n",
    "print(\"Average Word Length:\", stats['average_word_length'])\n",
    "print(\"Type-Token Ratio:\", stats['type_token_ratio'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
